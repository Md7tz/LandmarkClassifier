{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80de6795-08e3-47f1-99a8-1faa051b8597",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for Landmark Classification\n",
    "\n",
    "### A simple app\n",
    "\n",
    "In this notebook we build a very simple app that uses our exported model.\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Note how we are not importing anything from our source code (we do not use any module from the ``src`` directory). This is because the exported model, differently from the model weights, is a standalone serialization of our model and therefore it does not need anything else. You can ship that file to anybody, and as long as they can import ``torch``, they will be able to use your model. This is very important for releasing pytorch models to production.\n",
    "\n",
    "The app will show the top 5 classes that the model think are most relevant for the picture you have uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "807b8e16-b4ea-4cbc-bd56-a5b7670ef447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2ee467e6e044c0a733ed56bba28ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Please upload a picture of a landmark'), FileUpload(value=(), description='Upload'â€¦"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import VBox, Button, FileUpload, Output, Label\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "learn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\")\n",
    "\n",
    "# Define a function to process the image and classify it\n",
    "def on_click_classify(change):\n",
    "\n",
    "    # Load image that has been uploaded\n",
    "    fn = io.BytesIO(btn_upload.value[-1].content)\n",
    "\n",
    "    img = Image.open(fn)\n",
    "    img.load()\n",
    "\n",
    "    # Let's clear the previous output (if any)\n",
    "    out_pl.clear_output()\n",
    "\n",
    "    # Display the image\n",
    "    with out_pl:\n",
    "\n",
    "        ratio = img.size[0] / img.size[1]\n",
    "        c = img.copy()\n",
    "        c.thumbnail([ratio * 200, 200])\n",
    "        display(c)\n",
    "\n",
    "    # Transform to tensor\n",
    "    timg = T.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "    # Calling the model\n",
    "    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n",
    "    \n",
    "    # Get the indexes of the classes ordered by softmax\n",
    "    # (larger first)\n",
    "    idxs = np.argsort(softmax)[::-1]\n",
    "    \n",
    "    # Loop over the classes with the largest softmax\n",
    "    for i in range(5):\n",
    "        # Get softmax value\n",
    "        p = softmax[idxs[i]]\n",
    "    \n",
    "        # Get class name\n",
    "        landmark_name = learn_inf.class_names[idxs[i]]\n",
    "        # remove class index\n",
    "        landmark_name = landmark_name.split('.')[1]\n",
    "        \n",
    "        labels[i].value = f\"{landmark_name} (prob: {p:.2f}) {p*100:.2f}%\"\n",
    "\n",
    "\n",
    "# Putting back btn_upload to a widget for next cell\n",
    "btn_upload = FileUpload()\n",
    "\n",
    "btn_run = Button(description=\"Classify\")\n",
    "btn_run.on_click(on_click_classify)\n",
    "\n",
    "labels = []\n",
    "for _ in range(5):\n",
    "    labels.append(Label())\n",
    "\n",
    "out_pl = Output()\n",
    "out_pl.clear_output()\n",
    "\n",
    "wgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\n",
    "wgs.extend(labels)\n",
    "\n",
    "VBox(wgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8223465-ede1-4dd9-af44-bd7a24c3d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing jupyter nbconvert --to html app.ipynb\n",
      "Executing jupyter nbconvert --to html cnn_from_scratch.ipynb\n",
      "Executing jupyter nbconvert --to html transfer_learning.ipynb\n",
      "Adding files to submission_2023-10-27T16h40m.tar.gz\n",
      "src\\create_submit_pkg.py\n",
      "src\\data.py\n",
      "src\\helpers.py\n",
      "src\\model.py\n",
      "src\\optimization.py\n",
      "src\\predictor.py\n",
      "src\\train.py\n",
      "src\\transfer.py\n",
      "src\\__init__.py\n",
      "app.ipynb\n",
      "cnn_from_scratch.ipynb\n",
      "transfer_learning.ipynb\n",
      "app.html\n",
      "cnn_from_scratch.html\n",
      "transfer_learning.html\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Done. Please upload submission_2023-10-27T16h40m.tar.gz to the Udacity workspace\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook app.ipynb to html\n",
      "[NbConvertApp] Writing 281801 bytes to app.html\n",
      "[NbConvertApp] Converting notebook cnn_from_scratch.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 5 image(s).\n",
      "[NbConvertApp] Writing 2752314 bytes to cnn_from_scratch.html\n",
      "[NbConvertApp] Converting notebook transfer_learning.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 2 image(s).\n",
      "[NbConvertApp] Writing 1401535 bytes to transfer_learning.html\n"
     ]
    }
   ],
   "source": [
    "!python src/create_submit_pkg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04dcb4d-0ff1-46be-b897-4bb51d938a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
